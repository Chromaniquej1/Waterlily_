{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pfi3kdmHmWp",
        "outputId": "db665b0f-1568-469b-a989-3743989ac730"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows , Cols 101766 50\n",
            "target counts {'NO': 54864, '>30': 35545, '<30': 11357}\n",
            "top_missing\n",
            "weight                      96.86\n",
            "max_glu_serum               94.75\n",
            "A1Cresult                   83.28\n",
            "medical_specialty           49.08\n",
            "payer_code                  39.56\n",
            "race                         2.23\n",
            "diag_3                       1.40\n",
            "diag_2                       0.35\n",
            "diag_1                       0.02\n",
            "patient_nbr                  0.00\n",
            "time_in_hospital             0.00\n",
            "admission_source_id          0.00\n",
            "num_lab_procedures           0.00\n",
            "encounter_id                 0.00\n",
            "admission_type_id            0.00\n",
            "discharge_disposition_id     0.00\n",
            "gender                       0.00\n",
            "age                          0.00\n",
            "number_inpatient             0.00\n",
            "number_emergency             0.00\n",
            "number_outpatient            0.00\n",
            "num_medications              0.00\n",
            "num_procedures               0.00\n",
            "number_diagnoses             0.00\n",
            "metformin                    0.00\n",
            "repaglinide                  0.00\n",
            "nateglinide                  0.00\n",
            "chlorpropamide               0.00\n",
            "glimepiride                  0.00\n",
            "acetohexamide                0.00\n",
            "glipizide                    0.00\n",
            "glyburide                    0.00\n",
            "tolbutamide                  0.00\n",
            "pioglitazone                 0.00\n",
            "rosiglitazone                0.00\n",
            "acarbose                     0.00\n",
            "miglitol                     0.00\n",
            "troglitazone                 0.00\n",
            "tolazamide                   0.00\n",
            "examide                      0.00\n",
            "citoglipton                  0.00\n",
            "insulin                      0.00\n",
            "glyburide-metformin          0.00\n",
            "glipizide-metformin          0.00\n",
            "glimepiride-pioglitazone     0.00\n",
            "metformin-rosiglitazone      0.00\n",
            "metformin-pioglitazone       0.00\n",
            "change                       0.00\n",
            "diabetesMed                  0.00\n",
            "readmitted                   0.00\n",
            "dtype: float64\n",
            "cardinality {'medical_speciality': 72, 'diag1': 716, 'diag2': 748, 'diag3': 789}\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('/content/diabetic_data.csv')\n",
        "n_rows,n_cols = df.shape\n",
        "df = df.replace({\"?\":np.nan,\"None\":np.nan})\n",
        "target_counts = df['readmitted'].value_counts()\n",
        "target_pct = ((target_counts/target_counts.sum())*100).round(2)\n",
        "\n",
        "missing = df.isna().sum().sort_values(ascending=False)\n",
        "top_missing = (missing/len(df)*100).round(2)\n",
        "\n",
        "cardinality = {\n",
        "    \"medical_speciality\": int(df[\"medical_specialty\"].nunique(dropna=True)),\n",
        "    \"diag1\": int(df[\"diag_1\"].nunique(dropna=True)),\n",
        "    \"diag2\": int(df[\"diag_2\"].nunique(dropna=True)),\n",
        "    \"diag3\": int(df[\"diag_3\"].nunique(dropna=True))\n",
        "}\n",
        "\n",
        "print(\"Rows , Cols\",n_rows,n_cols)\n",
        "print(\"target counts\",target_counts.to_dict())\n",
        "print(\"top_missing\")\n",
        "print(top_missing)\n",
        "print(\"cardinality\",cardinality)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Modeliing"
      ],
      "metadata": {
        "id": "PEn_HWlpP0HX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
        "from sklearn.metrics import (roc_auc_score,average_precision_score,accuracy_score,f1_score,precision_score,recall_score)\n",
        "from joblib import dump\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ],
      "metadata": {
        "id": "fncppqQOPzsD"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/diabetic_data.csv')\n",
        "df = df.replace({\"?\":np.nan,\"None\":np.nan})\n",
        "\n",
        "EXCLUDE_DDISP = {11,19,20,21}\n",
        "if \"discharge_disposition_id\" in df.columns:\n",
        "    if \"discharge_disposition_id\" in df.columns:\n",
        "        df = df[~df[\"discharge_disposition_id\"].isin(EXCLUDE_DDISP)]\n",
        "for col in['weight','payer_code']:\n",
        "  if col in df.columns:\n",
        "    df = df.drop(columns = [col])\n",
        "\n",
        "engine = create_engine(\"sqlite:///diabetic_data.db\")\n",
        "df.to_sql(\"encounters\", con=engine,if_exists=\"replace\",index=False)\n",
        "print('Successfully created sqlite database')\n",
        "\n",
        "\n",
        "y = (df['readmitted'] == '<30').astype(int)\n",
        "\n",
        "keep_cols = [\n",
        "    \"race\",\"gender\",\"age\",\n",
        "    \"admission_type_id\",\"discharge_disposition_id\",\"admission_source_id\",\n",
        "    \"time_in_hospital\",\n",
        "    \"num_lab_procedures\",\"num_procedures\",\"num_medications\",\n",
        "    \"number_outpatient\",\"number_emergency\",\"number_inpatient\",\n",
        "    \"number_diagnoses\",\n",
        "    \"A1Cresult\",\"max_glu_serum\",\n",
        "    \"change\",\"diabetesMed\",\"insulin\"\n",
        "]\n",
        "X = df[keep_cols].copy()\n",
        "\n",
        "\n",
        "cat_cols = X.select_dtypes(include=\"object\").columns.tolist()\n",
        "num_cols = X.select_dtypes(exclude=\"object\").columns.tolist()\n",
        "\n",
        "preprocess = ColumnTransformer([\n",
        "    (\"cat\", Pipeline([\n",
        "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "        (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "    ]), cat_cols),\n",
        "    (\"num\", Pipeline([(\"imputer\", SimpleImputer(strategy=\"median\"))]), num_cols)\n",
        "])\n",
        "\n",
        "\n",
        "groups = df[\"patient_nbr\"].astype(str).values\n",
        "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
        "X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "model = {\n",
        "    \"LogistcRegression\": LogisticRegression(max_iter=400, class_weight = \"balanced\",random_state=42,n_jobs=1),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(n_estimators=200,class_weight=\"balanced\",random_state=42,n_jobs=1),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=\n",
        "                                                             42)\n",
        "}\n",
        "\n",
        "train_pipes = {}\n",
        "results = []\n",
        "\n",
        "for name, est in model.items():\n",
        "    pipe = Pipeline([\n",
        "        (\"preprocess\", preprocess),\n",
        "        (\"est\", est)\n",
        "    ])\n",
        "    pipe.fit(X_train, y_train)\n",
        "    proba = pipe.predict_proba(X_test)[:, 1]\n",
        "    preds  = pipe.predict(X_test)\n",
        "\n",
        "    roc = roc_auc_score(y_test, proba)\n",
        "    ap = average_precision_score(y_test, proba)\n",
        "    acc = accuracy_score(y_test, preds)\n",
        "    f1 = f1_score(y_test, preds)\n",
        "    prec = precision_score(y_test, preds)\n",
        "    rec = recall_score(y_test, preds)\n",
        "\n",
        "    results.append({\n",
        "        \"model\": name,\n",
        "        \"roc\": roc,\n",
        "        \"ap\": ap,\n",
        "        \"acc\": acc,\n",
        "        \"f1\": f1,\n",
        "        \"prec\": prec,\n",
        "        \"rec\": rec\n",
        "    })\n",
        "train_pipes[name] = pipe\n",
        "\n",
        "result_df = pd.DataFrame(results).round(3)\n",
        "results_df = result_df.sort_values(by=\"roc\", ascending=False)\n",
        "\n",
        "print(\"modelComaprison\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "\n",
        "best_name = results_df.iloc[0]['model']\n",
        "best_pipe = train_pipes[best_name]\n",
        "path = f\"/content/{best_name}_best_model.jolib\"\n",
        "dump(best_pipe, path)\n",
        "print(f\"Best model saved to {path}\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTr3fHJPQC44",
        "outputId": "7cead6bc-3f6c-44e9-a852-9063e4acf1ff"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully created sqlite database\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "modelComaprison\n",
            "                     model   roc    ap   acc    f1  prec   rec\n",
            "GradientBoostingClassifier 0.672 0.211 0.890 0.012 0.500 0.006\n",
            "         LogistcRegression 0.646 0.195 0.669 0.253 0.169 0.510\n",
            "    RandomForestClassifier 0.627 0.171 0.890 0.005 0.357 0.002\n",
            "Best model saved to /content/GradientBoostingClassifier_best_model.jolib\n"
          ]
        }
      ]
    }
  ]
}